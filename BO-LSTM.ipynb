{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04dc6bae",
   "metadata": {},
   "source": [
    "## 改造(時間遅れ変数、クロスタームの追加を別のコードで)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a2d165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, RBF, ConstantKernel, Matern, DotProduct\n",
    "import matplotlib.figure as figure\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn import metrics\n",
    "\n",
    "#LSTMの呼び出し\n",
    "# 同じディレクトリに LSTMwithAttention.py が存在する場合\n",
    "import LSTMwithAttention\n",
    "from LSTMwithAttention import LSTMWithOptionalAttention, Attention\n",
    "\n",
    "\n",
    "def bo_lstm_hyperparams(datasest, max_time_delay,\n",
    "                       validation_method='cv', bo_iteration_number=15, display_flag=False):\n",
    "    \n",
    "    \n",
    "    # ハイパーパラメータの探索候補\n",
    "    seq_length = [10, 50, 100, 300] #sliding_windowのサイズ\n",
    "    hidden_dim = [2, 4, 8, 16, 32] #隠れ層の数(小さめに設定)\n",
    "    batch_size = [4, 8, 16, 32]\n",
    "    lr= [1e-5, 1e-4, 1e-3, 1e-2] \n",
    "    dropout_rate = [0.2, 0.3, 0.4, 0.5]\n",
    "    use_attention = [True, False]  # Attention層を使うかどうかを選択 (True or False)\n",
    "        \n",
    "    # 実験計画法の条件\n",
    "    doe_number_of_selecting_samples = 15  # 選択するサンプル数\n",
    "    doe_number_of_random_searches = 100  # ランダムにサンプルを選択して D 最適基準を計算する繰り返し回数\n",
    "    # BOの設定\n",
    "    bo_iterations = np.arange(0, bo_iteration_number + 1)\n",
    "    bo_gp_fold_number = 5 # BOのGPを構築するためのcvfold数\n",
    "    bo_number_of_selecting_samples = 1  # 選択するサンプル数\n",
    "    #bo_regression_method = 'gpr_kernels'  # gpr_one_kernel', 'gpr_kernels'\n",
    "    bo_regression_method = 'gpr_one_kernel'  # gpr_one_kernel', 'gpr_kernels'\n",
    "    bo_kernel_number = 2  # 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n",
    "    acquisition_function = 'PTR'  # 'PTR', 'PI', 'EI', 'MI'\n",
    "    target_range = [1, 100]  # PTR\n",
    "    relaxation = 0.01  # EI, PI\n",
    "    delta = 10 ** -6  # MI\n",
    "    \n",
    "    # 解空間の作成\n",
    "    parameter_candidates = []\n",
    "    for window_size in seq_length:\n",
    "        for hidden in hidden_dim:\n",
    "            for batch in batch_size:\n",
    "                for learning_rate in lr:\n",
    "                    for attention in use_attention:\n",
    "                            for drop in dropout_rate:\n",
    "                                parameter_candidates.append([window_size, hidden, batch, learning_rate,\n",
    "                                                                         attention, drop])\n",
    "                                \n",
    "    all_candidate_combinations_df =  pd.DataFrame(parameter_candidates)\n",
    "    clm_name = ['window_size', 'hidden_dim', 'batch_size', 'learning_rate',\n",
    "               'attention', 'dropout_rate']\n",
    "    \n",
    "    all_candidate_combinations_df.columns = clm_name\n",
    "    \n",
    "    \n",
    "    numerical_variable_numbers = np.array([0, 1, 2, 3, 5])\n",
    "    category_variable_numbers = np.array([4])\n",
    "    category_columns = all_candidate_combinations_df.columns[category_variable_numbers]\n",
    "    #ワンホット変換\n",
    "    numerical_x = all_candidate_combinations_df.iloc[:, numerical_variable_numbers]\n",
    "    \n",
    "    category_x = all_candidate_combinations_df.iloc[:, category_variable_numbers].astype(int)\n",
    "    #dummy_x = pd.get_dummies(category_x, columns=category_columns).astype(int)\n",
    "    params_df = pd.concat([numerical_x, category_x], axis=1)\n",
    "    \n",
    "    #########################ここから#########################\n",
    "    \n",
    "    \n",
    "    # ベイズ最適化の繰り返し\n",
    "    for bo_iter in bo_iterations:\n",
    "        if display_flag:\n",
    "            print(f'Bayesian optimization iteration : {bo_iter + 1} / {bo_iteration_number}')\n",
    "    #    print('='*10)\n",
    "        if bo_iter == 0: # 最初の試行ではD最適基準を計算\n",
    "            # D最適基準の計算\n",
    "            autoscaled_params_df = (params_df - params_df.mean(axis=0)) / params_df.std(axis=0, ddof=1) # 計算のために標準化\n",
    "            all_indexes = list(range(autoscaled_params_df.shape[0])) # indexを取得\n",
    "    \n",
    "            np.random.seed(11) # 乱数を生成するためのシードを固定\n",
    "            for random_search_number in range(doe_number_of_random_searches):\n",
    "                # 1. ランダムに候補を選択\n",
    "                new_selected_indexes = np.random.choice(all_indexes, doe_number_of_selecting_samples, replace=False)\n",
    "                new_selected_samples = autoscaled_params_df.iloc[new_selected_indexes, :]\n",
    "                # 2. D 最適基準を計算\n",
    "                xt_x = np.dot(new_selected_samples.T, new_selected_samples)\n",
    "                d_optimal_value = np.linalg.det(xt_x) \n",
    "                # 3. D 最適基準が前回までの最大値を上回ったら、選択された候補を更新\n",
    "                if random_search_number == 0:\n",
    "                    best_d_optimal_value = d_optimal_value.copy()\n",
    "                    selected_sample_indexes = new_selected_indexes.copy()\n",
    "                else:\n",
    "                    if best_d_optimal_value < d_optimal_value:\n",
    "                        best_d_optimal_value = d_optimal_value.copy()\n",
    "                        selected_sample_indexes = new_selected_indexes.copy()\n",
    "            selected_sample_indexes = list(selected_sample_indexes) # リスト型に変換\n",
    "            \n",
    "            # 選択されたサンプル、選択されなかったサンプル\n",
    "            selected_params_df = params_df.iloc[selected_sample_indexes, :]  # 選択されたサンプル\n",
    "            true_selected_params_df = all_candidate_combinations_df.iloc[selected_sample_indexes, :]\n",
    "            bo_params_df = selected_params_df.copy() # BOのGPモデル構築用データを作成\n",
    "            remaining_indexes = np.delete(all_indexes, selected_sample_indexes)  # 選択されなかったサンプルのインデックス\n",
    "            remaining_params_df = params_df.iloc[remaining_indexes, :]  # 選択されなかったサンプル\n",
    "            true_remaining_params_df = all_candidate_combinations_df.iloc[remaining_indexes, :]\n",
    "    \n",
    "            # 選択された全候補でGMRの計算\n",
    "            params_with_score_df = params_df.copy() # cvのscoreが含まれるdataframe\n",
    "            params_with_score_df['score'] = np.nan # 初期値はnanを設定\n",
    "    \n",
    "        else: # 2回目以降では前回の結果をもとにする\n",
    "            selected_sample_indexes = next_samples_df.index # 提案サンプルのindex\n",
    "            selected_params_df = params_df.loc[selected_sample_indexes, :] # 次に計算するサンプル\n",
    "            true_selected_params_df = all_candidate_combinations_df.loc[selected_sample_indexes, :] # 次に計算するサンプル\n",
    "            bo_params_df = pd.concat([bo_params_df, selected_params_df], axis=0) # BOのGPモデル構築用データは前回のデータと提案サンプルをマージする\n",
    "            remaining_params_df = params_df.loc[params_with_score_df['score'].isna(), :] # 選択されなかったサンプル\n",
    "            remaining_params_df = remaining_params_df.drop(index=selected_sample_indexes)\n",
    "            true_remaining_params_df = all_candidate_combinations_df.loc[params_with_score_df['score'].isna(), :] # 選択されなかったサンプル\n",
    "            true_remaining_params_df = true_remaining_params_df.drop(index=selected_sample_indexes)\n",
    "    \n",
    "        # 選ばれたサンプル（パラメータの組み合わせ）を一つずつ計算する\n",
    "        for i_n, selected_params_idx in enumerate(selected_sample_indexes):\n",
    "            selected_params = true_selected_params_df.loc[selected_params_idx, :] # サンプルの選択\n",
    "            \n",
    "            #データ拡張の選択\n",
    "            selected_seq_length = selected_params['window_size']\n",
    "            selected_hidden_dim = selected_params['hidden_dim']\n",
    "            selected_batch_size = selected_params['batch_size']\n",
    "            selected_lr = selected_params['learning_rate']\n",
    "            selected_attention = selected_params['attention']\n",
    "            selected_dropout_late = selected_params['dropout_rate']\n",
    "\n",
    "            data = dataset.values.astype('float32')\n",
    "\n",
    "            inputs = data[:, 1:]\n",
    "            targets = data[:, 0]\n",
    "            \n",
    "            #ここで入力の次元が決まります\n",
    "            input_dim = dataset.shape[1] - 1\n",
    "\n",
    "            #window_sizeごとにデータを区切ります\n",
    "            input_sequences, target_sequences = create_sequences(inputs, targets, selected_seq_length)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                input_sequences, target_sequences, test_size=0.3, shuffle=False)\n",
    "\n",
    "            train_inputs_tensor = torch.tensor(X_train).float()\n",
    "            train_targets_tensor = torch.tensor(y_train).float().unsqueeze(1)\n",
    "\n",
    "            #test_inputs_tensor = torch.tensor(X_test).float()\n",
    "            #test_targets_tensor = torch.tensor(y_test).float().unsqueeze(1)\n",
    "\n",
    "            train_dataset = TensorDataset(train_inputs_tensor, train_targets_tensor)\n",
    "            #test_dataset = TensorDataset(test_inputs_tensor, test_targets_tensor)\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=int(selected_batch_size), shuffle=False)\n",
    "            #test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "            model = LSTMWithOptionalAttention(input_dim, int(selected_hidden_dim), output_dim, \n",
    "                                              selected_attention, selected_dropout_late)\n",
    "\n",
    "            # -------------------------------\n",
    "            # 学習準備（変更なし）\n",
    "            # -------------------------------\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            model.to(device)\n",
    "\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=selected_lr)\n",
    "            \n",
    "            \n",
    "            train_r2_scores = []\n",
    "            train_losses = []\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                model.train()\n",
    "                epoch_loss = 0\n",
    "                all_train_predictions = []\n",
    "                all_true_train_targets = []\n",
    "\n",
    "                for inputs, targets in train_loader:\n",
    "                    inputs = inputs.to(device)\n",
    "                    targets = targets.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs, _ = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                    # 訓練データの予測値を保存\n",
    "                    all_train_predictions.extend(outputs.detach().cpu().numpy().flatten())\n",
    "                    all_true_train_targets.extend(targets.detach().cpu().numpy().flatten())\n",
    "\n",
    "                avg_loss = epoch_loss / len(train_dataset)\n",
    "                train_losses.append(avg_loss)\n",
    "\n",
    "                # 訓練データ全体のR2スコアを計算\n",
    "                train_r2 = r2_score(all_true_train_targets, all_train_predictions)\n",
    "                #train_r2 = r2lm(all_true_train_targets, all_train_predictions)\n",
    "                train_r2_scores.append(train_r2)\n",
    "\n",
    "            params_with_score_df.loc[selected_params_idx, 'score'] = train_r2 # データの保存\n",
    "        if display_flag:\n",
    "            print('Best score :', params_with_score_df['score'].max())\n",
    "            print('='*10)\n",
    "        \n",
    "        # 最後はBOの計算をしないためbreak\n",
    "        if bo_iter + 1 == bo_iteration_number:\n",
    "            break\n",
    "                \n",
    "        # Bayesian optimization\n",
    "        bo_x_data = bo_params_df.copy() # GP学習用データはGMRの結果があるサンプル\n",
    "        bo_x_prediction = remaining_params_df.copy() # predictionは選択されていない（GMRの結果がない）サンプル\n",
    "        bo_y_data = params_with_score_df.loc[bo_params_df.index, 'score'] # yはGMRのr2cv\n",
    "        \n",
    "        # カーネル 11 種類\n",
    "        bo_kernels = [ConstantKernel() * DotProduct() + WhiteKernel(),\n",
    "                    ConstantKernel() * RBF() + WhiteKernel(),\n",
    "                    ConstantKernel() * RBF() + WhiteKernel() + ConstantKernel() * DotProduct(),\n",
    "                    ConstantKernel() * RBF(np.ones(bo_x_data.shape[1])) + WhiteKernel(),\n",
    "                    ConstantKernel() * RBF(np.ones(bo_x_data.shape[1])) + WhiteKernel() + ConstantKernel() * DotProduct(),\n",
    "                    ConstantKernel() * Matern(nu=1.5) + WhiteKernel(),\n",
    "                    ConstantKernel() * Matern(nu=1.5) + WhiteKernel() + ConstantKernel() * DotProduct(),\n",
    "                    ConstantKernel() * Matern(nu=0.5) + WhiteKernel(),\n",
    "                    ConstantKernel() * Matern(nu=0.5) + WhiteKernel() + ConstantKernel() * DotProduct(),\n",
    "                    ConstantKernel() * Matern(nu=2.5) + WhiteKernel(),\n",
    "                    ConstantKernel() * Matern(nu=2.5) + WhiteKernel() + ConstantKernel() * DotProduct()]\n",
    "    \n",
    "        next_samples = pd.DataFrame([], columns=selected_params_df.columns)  # 次のサンプルを入れる変数を準備\n",
    "    \n",
    "        # 次の候補を複数提案する繰り返し工程\n",
    "        for bo_sample_number in range(bo_number_of_selecting_samples):\n",
    "            # オートスケーリング\n",
    "            bo_x_data_std = bo_x_data.std()\n",
    "            bo_x_data_std[bo_x_data_std == 0] = 1\n",
    "            autoscaled_bo_y_data = (bo_y_data - bo_y_data.mean()) / bo_y_data.std()\n",
    "            autoscaled_bo_x_data = (bo_x_data - bo_x_data.mean()) / bo_x_data_std\n",
    "            autoscaled_bo_x_prediction = (bo_x_prediction - bo_x_data.mean()) / bo_x_data_std\n",
    "            \n",
    "            # モデル構築\n",
    "            if bo_regression_method == 'gpr_one_kernel':\n",
    "                bo_selected_kernel = bo_kernels[bo_kernel_number]\n",
    "                bo_model = GaussianProcessRegressor(alpha=0, kernel=bo_selected_kernel)\n",
    "    \n",
    "            elif bo_regression_method == 'gpr_kernels':\n",
    "                # クロスバリデーションによるカーネル関数の最適化\n",
    "                bo_cross_validation = KFold(n_splits=bo_gp_fold_number, random_state=9, shuffle=True) # クロスバリデーションの分割の設定\n",
    "                bo_r2cvs = [] # 空の list。カーネル関数ごとに、クロスバリデーション後の r2 を入れていきます\n",
    "                for index, bo_kernel in enumerate(bo_kernels):\n",
    "                    bo_model = GaussianProcessRegressor(alpha=0, kernel=bo_kernel)\n",
    "                    estimated_bo_y_in_cv = np.ndarray.flatten(cross_val_predict(bo_model, autoscaled_bo_x_data, autoscaled_bo_y_data, cv=bo_cross_validation))\n",
    "                    estimated_bo_y_in_cv = estimated_bo_y_in_cv * bo_y_data.std(ddof=1) + bo_y_data.mean()\n",
    "                    bo_r2cvs.append(r2_score(bo_y_data, estimated_bo_y_in_cv))\n",
    "                optimal_bo_kernel_number = np.where(bo_r2cvs == np.max(bo_r2cvs))[0][0]  # クロスバリデーション後の r2 が最も大きいカーネル関数の番号\n",
    "                optimal_bo_kernel = bo_kernels[optimal_bo_kernel_number]  # クロスバリデーション後の r2 が最も大きいカーネル関数\n",
    "                \n",
    "                # モデル構築\n",
    "                bo_model = GaussianProcessRegressor(alpha=0, kernel=optimal_bo_kernel, random_state=9) # GPR モデルの宣言\n",
    "                \n",
    "            bo_model.fit(autoscaled_bo_x_data, autoscaled_bo_y_data)  # モデルの学習\n",
    "            \n",
    "            # 予測\n",
    "            estimated_bo_y_prediction, estimated_bo_y_prediction_std = bo_model.predict(autoscaled_bo_x_prediction, return_std=True)\n",
    "            estimated_bo_y_prediction = estimated_bo_y_prediction * bo_y_data.std() + bo_y_data.mean()\n",
    "            estimated_bo_y_prediction_std = estimated_bo_y_prediction_std * bo_y_data.std()\n",
    "            \n",
    "            cumulative_variance = np.zeros(bo_x_prediction.shape[0])\n",
    "            # 獲得関数の計算\n",
    "            if acquisition_function == 'MI':\n",
    "                acquisition_function_prediction = estimated_bo_y_prediction + np.log(2 / delta) ** 0.5 * (\n",
    "                        (estimated_bo_y_prediction_std ** 2 + cumulative_variance) ** 0.5 - cumulative_variance ** 0.5)\n",
    "                cumulative_variance = cumulative_variance + estimated_bo_y_prediction_std ** 2\n",
    "            elif acquisition_function == 'EI':\n",
    "                acquisition_function_prediction = (estimated_bo_y_prediction - max(bo_y_data) - relaxation * bo_y_data.std()) * \\\n",
    "                                                norm.cdf((estimated_bo_y_prediction - max(bo_y_data) - relaxation * bo_y_data.std()) /\n",
    "                                                            estimated_bo_y_prediction_std) + \\\n",
    "                                                estimated_bo_y_prediction_std * \\\n",
    "                                                norm.pdf((estimated_bo_y_prediction - max(bo_y_data) - relaxation * bo_y_data.std()) /\n",
    "                                                            estimated_bo_y_prediction_std)\n",
    "            elif acquisition_function == 'PI':\n",
    "                acquisition_function_prediction = norm.cdf(\n",
    "                        (estimated_bo_y_prediction - max(bo_y_data) - relaxation * bo_y_data.std()) / estimated_bo_y_prediction_std)\n",
    "            elif acquisition_function == 'PTR':\n",
    "                acquisition_function_prediction = norm.cdf(target_range[1],\n",
    "                                                        loc=estimated_bo_y_prediction,\n",
    "                                                        scale=estimated_bo_y_prediction_std\n",
    "                                                        ) - norm.cdf(target_range[0],\n",
    "                                                                        loc=estimated_bo_y_prediction,\n",
    "                                                                        scale=estimated_bo_y_prediction_std)\n",
    "            acquisition_function_prediction[estimated_bo_y_prediction_std <= 0] = 0\n",
    "            \n",
    "            # 保存\n",
    "            estimated_bo_y_prediction = pd.DataFrame(estimated_bo_y_prediction, bo_x_prediction.index, columns=['estimated_y'])\n",
    "            estimated_bo_y_prediction_std = pd.DataFrame(estimated_bo_y_prediction_std, bo_x_prediction.index, columns=['std_of_estimated_y'])\n",
    "            acquisition_function_prediction = pd.DataFrame(acquisition_function_prediction, index=bo_x_prediction.index, columns=['acquisition_function'])\n",
    "    #        \n",
    "            # 次のサンプル\n",
    "            next_samples = pd.concat([next_samples, bo_x_prediction.loc[acquisition_function_prediction.idxmax()]], axis=0)\n",
    "            \n",
    "            # x, y, x_prediction, cumulative_variance の更新\n",
    "            bo_x_data = pd.concat([bo_x_data, bo_x_prediction.loc[acquisition_function_prediction.idxmax()]], axis=0)\n",
    "            bo_y_data = pd.concat([bo_y_data, estimated_bo_y_prediction.loc[acquisition_function_prediction.idxmax()].iloc[0]], axis=0)\n",
    "            bo_x_prediction = bo_x_prediction.drop(acquisition_function_prediction.idxmax(), axis=0)\n",
    "            cumulative_variance = np.delete(cumulative_variance, np.where(acquisition_function_prediction.index == acquisition_function_prediction.iloc[:, 0].idxmax())[0][0])\n",
    "        next_samples_df = next_samples.copy()\n",
    "    \n",
    "    # 結果の保存\n",
    "    #params_with_score_df.sort_values('score', ascending=False).to_csv('params_with_score.csv')\n",
    "    print(params_with_score_df)\n",
    "    params_with_score_df_best = params_with_score_df.sort_values('score', ascending=False).iloc[0, :] # r2が高い順にソー\n",
    "    #best_r2\n",
    "    \n",
    "    optimal_window_size = params_with_score_df_best.iloc[0]\n",
    "    optimal_hidden_dim = params_with_score_df_best.iloc[1]\n",
    "    optimal_batch_size = params_with_score_df_best.iloc[2]\n",
    "    optimal_learning_rate = params_with_score_df_best.iloc[3]\n",
    "    optimal_dropout_rate = params_with_score_df_best.iloc[4]\n",
    "    if int(params_with_score_df_best.iloc[5]) == 1:\n",
    "        optimal_attention = True\n",
    "    else:\n",
    "        optimal_attention = False\n",
    "        \n",
    "    #optimal_hidden_layer_sizes = hidden_layer_sizes_candidates[int(best_candidate_combination.iloc[0])]\n",
    "    #optimal_activation = activation_candidates[int(best_candidate_combination.iloc[1])]\n",
    "    #optimal_alpha = best_candidate_combination.iloc[2]\n",
    "    #optimal_learning_rate_init = best_candidate_combination.iloc[3]\n",
    "    \n",
    "    \"\"\"\n",
    "    input_dimが変わらないのであれば、最適化したmodelをreturn\n",
    "    最適化しないのであれば、最適値をリターン\n",
    "    \"\"\"\n",
    "       \n",
    "    return optimal_window_size, optimal_hidden_dim, optimal_batch_size, optimal_learning_rate, optimal_dropout_rate, optimal_attention\n",
    "\n",
    "    \n",
    "# Calculate r^2 based on the latest measured y-values\n",
    "# measured_y and estimated_y must be vectors.\n",
    "def r2lm(measured_y, estimated_y):\n",
    "    measured_y = np.array(measured_y).flatten()\n",
    "    estimated_y = np.array(estimated_y).flatten()\n",
    "    return float(1 - sum((measured_y - estimated_y) ** 2) / sum((measured_y[1:] - measured_y[:-1]) ** 2))\n",
    "\n",
    "def create_sequences(data, target, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        xs.append(data[i:i+seq_length])\n",
    "        ys.append(target[i+seq_length])\n",
    "        return np.array(xs), np.array(ys)\n",
    "        \n",
    "\n",
    "output_dim=1\n",
    "num_epochs = 10\n",
    "dataset = pd.read_csv('sample_dataset.csv', index_col=0)\n",
    "(optimal_window_size, optimal_hidden_dim, optimal_batch_size, optimal_learning_rate, optimal_dropout_rate, optimal_attention) = bo_lstm_hyperparams(dataset, max_time_delay,\n",
    "                                                                                                                                                    validation_method='cv', bo_iteration_number=15, display_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc5180e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koishikawa\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian optimization iteration : 1 / 15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 354\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(xs), np\u001b[38;5;241m.\u001b[39marray(ys)\n\u001b[0;32m    353\u001b[0m dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 354\u001b[0m (optimal_window_size, optimal_hidden_dim, optimal_batch_size, optimal_learning_rate, optimal_dropout_rate, optimal_attention) \u001b[38;5;241m=\u001b[39m bo_lstm_hyperparams(dataset,num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, bo_iteration_number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, display_flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[1], line 190\u001b[0m, in \u001b[0;36mbo_lstm_hyperparams\u001b[1;34m(datasest, num_epochs, bo_iteration_number, display_flag)\u001b[0m\n\u001b[0;32m    187\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    189\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 190\u001b[0m outputs, _ \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m    191\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m    192\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\BO_LSTM\\LSTMwithAttention.py:24\u001b[0m, in \u001b[0;36mLSTMWithOptionalAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m lstm_out_dropped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(lstm_out) \u001b[38;5;66;03m# LSTM出力にドロップアウト適用\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_attention:\n\u001b[1;32m---> 24\u001b[0m     context_vector, attention_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(lstm_out_dropped)\n\u001b[0;32m     25\u001b[0m     combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((lstm_out_dropped[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :], context_vector[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     26\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(combined)) \u001b[38;5;66;03m# 結合後の特徴量にドロップアウト適用\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\BO_LSTM\\LSTMwithAttention.py:43\u001b[0m, in \u001b[0;36mAttention.forward\u001b[1;34m(self, lstm_output)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, lstm_output):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# lstm_output: (batch_size, seq_len, hidden_dim)\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     attn_scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(lstm_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_proj(lstm_output)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# attn_scores: (batch_size, seq_len, seq_len)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(attn_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, RBF, ConstantKernel, Matern, DotProduct\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#LSTMの呼び出し\n",
    "from LSTMwithAttention import LSTMWithOptionalAttention, Attention\n",
    "\n",
    "def bo_lstm_hyperparams(datasest, num_epochs, bo_iteration_number=15, display_flag=False):\n",
    "    \n",
    "    #固定のパラメータ\n",
    "    #入力次元\n",
    "    input_dim = dataset.shape[1] - 1\n",
    "    \n",
    "    #出力次元\n",
    "    output_dim=1\n",
    "    \n",
    "    # ハイパーパラメータの探索候補\n",
    "    seq_length = [10, 50, 100, 300] #sliding_windowのサイズ\n",
    "    hidden_dim = [2, 4, 8, 16, 32] #隠れ層の数(小さめに設定)\n",
    "    batch_size = [4, 8, 16, 32]\n",
    "    lr= [1e-5, 1e-4, 1e-3, 1e-2] \n",
    "    dropout_rate = [0.2, 0.3, 0.4, 0.5]\n",
    "    use_attention = [True, False]  # Attention層を使うかどうかを選択 (True or False)\n",
    "        \n",
    "    # 実験計画法の条件\n",
    "    doe_number_of_selecting_samples = 3  # 選択するサンプル数\n",
    "    doe_number_of_random_searches = 100  # ランダムにサンプルを選択して D 最適基準を計算する繰り返し回数\n",
    "    # BOの設定\n",
    "    bo_iterations = np.arange(0, bo_iteration_number + 1)\n",
    "    bo_gp_fold_number = 5 # BOのGPを構築するためのcvfold数\n",
    "    bo_number_of_selecting_samples = 1  # 選択するサンプル数\n",
    "    #bo_regression_method = 'gpr_kernels'  # gpr_one_kernel', 'gpr_kernels'\n",
    "    bo_regression_method = 'gpr_one_kernel'  # gpr_one_kernel', 'gpr_kernels'\n",
    "    bo_kernel_number = 2  # 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n",
    "    acquisition_function = 'PTR'  # 'PTR', 'PI', 'EI', 'MI'\n",
    "    target_range = [1, 100]  # PTR\n",
    "    relaxation = 0.01  # EI, PI\n",
    "    delta = 10 ** -6  # MI\n",
    "    \n",
    "    # 解空間の作成\n",
    "    parameter_candidates = []\n",
    "    for window_size in seq_length:\n",
    "        for hidden in hidden_dim:\n",
    "            for batch in batch_size:\n",
    "                for learning_rate in lr:\n",
    "                    for attention in use_attention:\n",
    "                            for drop in dropout_rate:\n",
    "                                parameter_candidates.append([window_size, hidden, batch, learning_rate,\n",
    "                                                                         attention, drop])\n",
    "                                \n",
    "    all_candidate_combinations_df =  pd.DataFrame(parameter_candidates)\n",
    "    clm_name = ['window_size', 'hidden_dim', 'batch_size', 'learning_rate',\n",
    "               'attention', 'dropout_rate']\n",
    "    \n",
    "    all_candidate_combinations_df.columns = clm_name\n",
    "    \n",
    "    \n",
    "    numerical_variable_numbers = np.array([0, 1, 2, 3, 5])\n",
    "    category_variable_numbers = np.array([4])\n",
    "    category_columns = all_candidate_combinations_df.columns[category_variable_numbers]\n",
    "    #ワンホット変換\n",
    "    numerical_x = all_candidate_combinations_df.iloc[:, numerical_variable_numbers]\n",
    "    category_x = all_candidate_combinations_df.iloc[:, category_variable_numbers].astype(int)\n",
    "    #dummy_x = pd.get_dummies(category_x, columns=category_columns).astype(int)\n",
    "    params_df = pd.concat([numerical_x, category_x], axis=1)\n",
    "    \n",
    "    #########################ここからベイズ最適化#########################\n",
    "    \n",
    "    # ベイズ最適化の繰り返し\n",
    "    for bo_iter in bo_iterations:\n",
    "        if display_flag:\n",
    "            print(f'Bayesian optimization iteration : {bo_iter + 1} / {bo_iteration_number}')\n",
    "    #    print('='*10)\n",
    "        if bo_iter == 0: # 最初の試行ではD最適基準を計算\n",
    "            # D最適基準の計算\n",
    "            autoscaled_params_df = (params_df - params_df.mean(axis=0)) / params_df.std(axis=0, ddof=1) # 計算のために標準化\n",
    "            all_indexes = list(range(autoscaled_params_df.shape[0])) # indexを取得\n",
    "    \n",
    "            np.random.seed(11) # 乱数を生成するためのシードを固定\n",
    "            for random_search_number in range(doe_number_of_random_searches):\n",
    "                # 1. ランダムに候補を選択\n",
    "                new_selected_indexes = np.random.choice(all_indexes, doe_number_of_selecting_samples, replace=False)\n",
    "                new_selected_samples = autoscaled_params_df.iloc[new_selected_indexes, :]\n",
    "                # 2. D 最適基準を計算\n",
    "                xt_x = np.dot(new_selected_samples.T, new_selected_samples)\n",
    "                d_optimal_value = np.linalg.det(xt_x) \n",
    "                # 3. D 最適基準が前回までの最大値を上回ったら、選択された候補を更新\n",
    "                if random_search_number == 0:\n",
    "                    best_d_optimal_value = d_optimal_value.copy()\n",
    "                    selected_sample_indexes = new_selected_indexes.copy()\n",
    "                else:\n",
    "                    if best_d_optimal_value < d_optimal_value:\n",
    "                        best_d_optimal_value = d_optimal_value.copy()\n",
    "                        selected_sample_indexes = new_selected_indexes.copy()\n",
    "            selected_sample_indexes = list(selected_sample_indexes) # リスト型に変換\n",
    "            \n",
    "            # 選択されたサンプル、選択されなかったサンプル\n",
    "            selected_params_df = params_df.iloc[selected_sample_indexes, :]  # 選択されたサンプル\n",
    "            true_selected_params_df = all_candidate_combinations_df.iloc[selected_sample_indexes, :]\n",
    "            bo_params_df = selected_params_df.copy() # BOのGPモデル構築用データを作成\n",
    "            remaining_indexes = np.delete(all_indexes, selected_sample_indexes)  # 選択されなかったサンプルのインデックス\n",
    "            remaining_params_df = params_df.iloc[remaining_indexes, :]  # 選択されなかったサンプル\n",
    "            true_remaining_params_df = all_candidate_combinations_df.iloc[remaining_indexes, :]\n",
    "    \n",
    "            # 選択された全候補でGPRの計算\n",
    "            params_with_score_df = params_df.copy() # cvのscoreが含まれるdataframe\n",
    "            params_with_score_df['score'] = np.nan # 初期値はnanを設定\n",
    "    \n",
    "        else: # 2回目以降では前回の結果をもとにする\n",
    "            selected_sample_indexes = next_samples_df.index # 提案サンプルのindex\n",
    "            selected_params_df = params_df.loc[selected_sample_indexes, :] # 次に計算するサンプル\n",
    "            true_selected_params_df = all_candidate_combinations_df.loc[selected_sample_indexes, :] # 次に計算するサンプル\n",
    "            bo_params_df = pd.concat([bo_params_df, selected_params_df], axis=0) # BOのGPモデル構築用データは前回のデータと提案サンプルをマージする\n",
    "            remaining_params_df = params_df.loc[params_with_score_df['score'].isna(), :] # 選択されなかったサンプル\n",
    "            remaining_params_df = remaining_params_df.drop(index=selected_sample_indexes)\n",
    "            true_remaining_params_df = all_candidate_combinations_df.loc[params_with_score_df['score'].isna(), :] # 選択されなかったサンプル\n",
    "            true_remaining_params_df = true_remaining_params_df.drop(index=selected_sample_indexes)\n",
    "    \n",
    "        # 選ばれたサンプル（パラメータの組み合わせ）を一つずつ計算する\n",
    "        for i_n, selected_params_idx in enumerate(selected_sample_indexes):\n",
    "            selected_params = true_selected_params_df.loc[selected_params_idx, :] # サンプルの選択\n",
    "            \n",
    "            #データ拡張の選択\n",
    "            selected_seq_length = selected_params['window_size']\n",
    "            selected_hidden_dim = selected_params['hidden_dim']\n",
    "            selected_batch_size = selected_params['batch_size']\n",
    "            selected_lr = selected_params['learning_rate']\n",
    "            selected_attention = selected_params['attention']\n",
    "            selected_dropout_late = selected_params['dropout_rate']\n",
    "\n",
    "            data = dataset.values.astype('float32')\n",
    "\n",
    "            inputs = data[:, 1:]\n",
    "            targets = data[:, 0]\n",
    "\n",
    "            #window_sizeごとにデータを区切ります\n",
    "            input_sequences, target_sequences = create_sequences(inputs, targets, selected_seq_length)\n",
    "\n",
    "            inputs_tensor = torch.tensor(input_sequences).float()\n",
    "            targets_tensor = torch.tensor(target_sequences).float().unsqueeze(1)\n",
    "\n",
    "            dataset_tensor = TensorDataset(inputs_tensor, targets_tensor)\n",
    "\n",
    "            train_loader = DataLoader(dataset_tensor, batch_size=int(selected_batch_size), shuffle=False)\n",
    "            \n",
    "            model = LSTMWithOptionalAttention(input_dim, int(selected_hidden_dim), output_dim, \n",
    "                                              selected_attention, selected_dropout_late)\n",
    "\n",
    "            # -------------------------------\n",
    "            # 学習準備（変更なし）\n",
    "            # -------------------------------\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            model.to(device)\n",
    "\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=selected_lr)\n",
    "            \n",
    "            \n",
    "            train_r2_scores = []\n",
    "            train_losses = []\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                model.train()\n",
    "                epoch_loss = 0\n",
    "                all_train_predictions = []\n",
    "                all_true_train_targets = []\n",
    "\n",
    "                for inputs, targets in train_loader:\n",
    "                    inputs = inputs.to(device)\n",
    "                    targets = targets.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs, _ = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                    # 訓練データの予測値を保存\n",
    "                    all_train_predictions.extend(outputs.detach().cpu().numpy().flatten())\n",
    "                    all_true_train_targets.extend(targets.detach().cpu().numpy().flatten())\n",
    "\n",
    "                avg_loss = epoch_loss / len(dataset_tensor)\n",
    "                train_losses.append(avg_loss)\n",
    "\n",
    "                # 訓練データ全体のR2スコアを計算\n",
    "                train_r2 = r2_score(all_true_train_targets, all_train_predictions)\n",
    "                #train_r2 = r2lm(all_true_train_targets, all_train_predictions)\n",
    "                train_r2_scores.append(train_r2)\n",
    "\n",
    "            params_with_score_df.loc[selected_params_idx, 'score'] = train_r2 # データの保存\n",
    "        if display_flag:\n",
    "            print('Best score :', params_with_score_df['score'].max())\n",
    "            print('='*10)\n",
    "        \n",
    "        # 最後はBOの計算をしないためbreak\n",
    "        if bo_iter + 1 == bo_iteration_number:\n",
    "            break\n",
    "                \n",
    "        # Bayesian optimization\n",
    "        bo_x_data = bo_params_df.copy() # GP学習用データはGMRの結果があるサンプル\n",
    "        bo_x_prediction = remaining_params_df.copy() # predictionは選択されていない（GMRの結果がない）サンプル\n",
    "        bo_y_data = params_with_score_df.loc[bo_params_df.index, 'score'] # yはGMRのr2cv\n",
    "        \n",
    "        # カーネル 11 種類\n",
    "        bo_kernels = [ConstantKernel() * DotProduct() + WhiteKernel(),\n",
    "                    ConstantKernel() * RBF() + WhiteKernel(),\n",
    "                    ConstantKernel() * RBF() + WhiteKernel() + ConstantKernel() * DotProduct(),\n",
    "                    ConstantKernel() * RBF(np.ones(bo_x_data.shape[1])) + WhiteKernel(),\n",
    "                    ConstantKernel() * RBF(np.ones(bo_x_data.shape[1])) + WhiteKernel() + ConstantKernel() * DotProduct(),\n",
    "                    ConstantKernel() * Matern(nu=1.5) + WhiteKernel(),\n",
    "                    ConstantKernel() * Matern(nu=1.5) + WhiteKernel() + ConstantKernel() * DotProduct(),\n",
    "                    ConstantKernel() * Matern(nu=0.5) + WhiteKernel(),\n",
    "                    ConstantKernel() * Matern(nu=0.5) + WhiteKernel() + ConstantKernel() * DotProduct(),\n",
    "                    ConstantKernel() * Matern(nu=2.5) + WhiteKernel(),\n",
    "                    ConstantKernel() * Matern(nu=2.5) + WhiteKernel() + ConstantKernel() * DotProduct()]\n",
    "    \n",
    "        next_samples = pd.DataFrame([], columns=selected_params_df.columns)  # 次のサンプルを入れる変数を準備\n",
    "    \n",
    "        # 次の候補を複数提案する繰り返し工程\n",
    "        for bo_sample_number in range(bo_number_of_selecting_samples):\n",
    "            # オートスケーリング\n",
    "            bo_x_data_std = bo_x_data.std()\n",
    "            bo_x_data_std[bo_x_data_std == 0] = 1\n",
    "            autoscaled_bo_y_data = (bo_y_data - bo_y_data.mean()) / bo_y_data.std()\n",
    "            autoscaled_bo_x_data = (bo_x_data - bo_x_data.mean()) / bo_x_data_std\n",
    "            autoscaled_bo_x_prediction = (bo_x_prediction - bo_x_data.mean()) / bo_x_data_std\n",
    "            \n",
    "            # モデル構築\n",
    "            if bo_regression_method == 'gpr_one_kernel':\n",
    "                bo_selected_kernel = bo_kernels[bo_kernel_number]\n",
    "                bo_model = GaussianProcessRegressor(alpha=0, kernel=bo_selected_kernel)\n",
    "    \n",
    "            elif bo_regression_method == 'gpr_kernels':\n",
    "                # クロスバリデーションによるカーネル関数の最適化\n",
    "                bo_cross_validation = KFold(n_splits=bo_gp_fold_number, random_state=9, shuffle=True) # クロスバリデーションの分割の設定\n",
    "                bo_r2cvs = [] # 空の list。カーネル関数ごとに、クロスバリデーション後の r2 を入れていきます\n",
    "                for index, bo_kernel in enumerate(bo_kernels):\n",
    "                    bo_model = GaussianProcessRegressor(alpha=0, kernel=bo_kernel)\n",
    "                    estimated_bo_y_in_cv = np.ndarray.flatten(cross_val_predict(bo_model, autoscaled_bo_x_data, autoscaled_bo_y_data, cv=bo_cross_validation))\n",
    "                    estimated_bo_y_in_cv = estimated_bo_y_in_cv * bo_y_data.std(ddof=1) + bo_y_data.mean()\n",
    "                    bo_r2cvs.append(r2_score(bo_y_data, estimated_bo_y_in_cv))\n",
    "                optimal_bo_kernel_number = np.where(bo_r2cvs == np.max(bo_r2cvs))[0][0]  # クロスバリデーション後の r2 が最も大きいカーネル関数の番号\n",
    "                optimal_bo_kernel = bo_kernels[optimal_bo_kernel_number]  # クロスバリデーション後の r2 が最も大きいカーネル関数\n",
    "                \n",
    "                # モデル構築\n",
    "                bo_model = GaussianProcessRegressor(alpha=0, kernel=optimal_bo_kernel, random_state=9) # GPR モデルの宣言\n",
    "                \n",
    "            bo_model.fit(autoscaled_bo_x_data, autoscaled_bo_y_data)  # モデルの学習\n",
    "            \n",
    "            # 予測\n",
    "            estimated_bo_y_prediction, estimated_bo_y_prediction_std = bo_model.predict(autoscaled_bo_x_prediction, return_std=True)\n",
    "            estimated_bo_y_prediction = estimated_bo_y_prediction * bo_y_data.std() + bo_y_data.mean()\n",
    "            estimated_bo_y_prediction_std = estimated_bo_y_prediction_std * bo_y_data.std()\n",
    "            \n",
    "            cumulative_variance = np.zeros(bo_x_prediction.shape[0])\n",
    "            # 獲得関数の計算\n",
    "            if acquisition_function == 'MI':\n",
    "                acquisition_function_prediction = estimated_bo_y_prediction + np.log(2 / delta) ** 0.5 * (\n",
    "                        (estimated_bo_y_prediction_std ** 2 + cumulative_variance) ** 0.5 - cumulative_variance ** 0.5)\n",
    "                cumulative_variance = cumulative_variance + estimated_bo_y_prediction_std ** 2\n",
    "            elif acquisition_function == 'EI':\n",
    "                acquisition_function_prediction = (estimated_bo_y_prediction - max(bo_y_data) - relaxation * bo_y_data.std()) * \\\n",
    "                                                norm.cdf((estimated_bo_y_prediction - max(bo_y_data) - relaxation * bo_y_data.std()) /\n",
    "                                                            estimated_bo_y_prediction_std) + \\\n",
    "                                                estimated_bo_y_prediction_std * \\\n",
    "                                                norm.pdf((estimated_bo_y_prediction - max(bo_y_data) - relaxation * bo_y_data.std()) /\n",
    "                                                            estimated_bo_y_prediction_std)\n",
    "            elif acquisition_function == 'PI':\n",
    "                acquisition_function_prediction = norm.cdf(\n",
    "                        (estimated_bo_y_prediction - max(bo_y_data) - relaxation * bo_y_data.std()) / estimated_bo_y_prediction_std)\n",
    "            elif acquisition_function == 'PTR':\n",
    "                acquisition_function_prediction = norm.cdf(target_range[1],\n",
    "                                                        loc=estimated_bo_y_prediction,\n",
    "                                                        scale=estimated_bo_y_prediction_std\n",
    "                                                        ) - norm.cdf(target_range[0],\n",
    "                                                                        loc=estimated_bo_y_prediction,\n",
    "                                                                        scale=estimated_bo_y_prediction_std)\n",
    "            acquisition_function_prediction[estimated_bo_y_prediction_std <= 0] = 0\n",
    "            \n",
    "            # 保存\n",
    "            estimated_bo_y_prediction = pd.DataFrame(estimated_bo_y_prediction, bo_x_prediction.index, columns=['estimated_y'])\n",
    "            estimated_bo_y_prediction_std = pd.DataFrame(estimated_bo_y_prediction_std, bo_x_prediction.index, columns=['std_of_estimated_y'])\n",
    "            acquisition_function_prediction = pd.DataFrame(acquisition_function_prediction, index=bo_x_prediction.index, columns=['acquisition_function'])\n",
    "    #        \n",
    "            # 次のサンプル\n",
    "            next_samples = pd.concat([next_samples, bo_x_prediction.loc[acquisition_function_prediction.idxmax()]], axis=0)\n",
    "            \n",
    "            # x, y, x_prediction, cumulative_variance の更新\n",
    "            bo_x_data = pd.concat([bo_x_data, bo_x_prediction.loc[acquisition_function_prediction.idxmax()]], axis=0)\n",
    "            bo_y_data = pd.concat([bo_y_data, estimated_bo_y_prediction.loc[acquisition_function_prediction.idxmax()].iloc[0]], axis=0)\n",
    "            bo_x_prediction = bo_x_prediction.drop(acquisition_function_prediction.idxmax(), axis=0)\n",
    "            cumulative_variance = np.delete(cumulative_variance, np.where(acquisition_function_prediction.index == acquisition_function_prediction.iloc[:, 0].idxmax())[0][0])\n",
    "        next_samples_df = next_samples.copy()\n",
    "    \n",
    "    # 結果の保存\n",
    "    #params_with_score_df.sort_values('score', ascending=False).to_csv('params_with_score.csv')\n",
    "    #print(params_with_score_df)\n",
    "    params_with_score_df_best = params_with_score_df.sort_values('score', ascending=False).iloc[0, :] # r2が高い順にソー\n",
    "    #best_r2\n",
    "    \n",
    "    optimal_window_size = params_with_score_df_best.iloc[0] #最適な窓サイズ\n",
    "    optimal_hidden_dim = params_with_score_df_best.iloc[1] #最適な隠れ層サイズ\n",
    "    optimal_batch_size = params_with_score_df_best.iloc[2] # 最適なバッチサイズ\n",
    "    optimal_learning_rate = params_with_score_df_best.iloc[3] #最適な学習率\n",
    "    optimal_dropout_rate = params_with_score_df_best.iloc[4] #最適なドロップアウト率\n",
    "    if int(params_with_score_df_best.iloc[5]) == 1: #アテンションを適応させるかどうか\n",
    "        optimal_attention = True\n",
    "    else:\n",
    "        optimal_attention = False\n",
    "    \n",
    "    \"\"\"\n",
    "    input_dimが変わらないのであれば、最適化したmodelをreturn\n",
    "    最適化しないのであれば、最適値をリターン\n",
    "    \"\"\"\n",
    "    model = LSTMWithOptionalAttention(input_dim, optimal_hidden_dim, output_dim, \n",
    "                                              optimal_attention, optimal_dropout_rate)\n",
    "    #return optimal_window_size, optimal_hidden_dim, optimal_batch_size, optimal_learning_rate, optimal_dropout_rate, optimal_attention\n",
    "    return model, optimal_window_size, optimal_batch_size\n",
    "\n",
    "    \n",
    "# Calculate r^2 based on the latest measured y-values\n",
    "# measured_y and estimated_y must be vectors.\n",
    "def r2lm(measured_y, estimated_y):\n",
    "    measured_y = np.array(measured_y).flatten()\n",
    "    estimated_y = np.array(estimated_y).flatten()\n",
    "    return float(1 - sum((measured_y - estimated_y) ** 2) / sum((measured_y[1:] - measured_y[:-1]) ** 2))\n",
    "\n",
    "def create_sequences(data, target, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        xs.append(data[i:i+seq_length])\n",
    "        ys.append(target[i+seq_length])\n",
    "    return np.array(xs), np.array(ys)\n",
    "        \n",
    "\n",
    "dataset = pd.read_csv('sample_dataset.csv', index_col=0)\n",
    "#(optimal_window_size, optimal_hidden_dim, optimal_batch_size, optimal_learning_rate, optimal_dropout_rate, optimal_attention) = bo_lstm_hyperparams(dataset,num_epochs = 10, bo_iteration_number=15, display_flag=True)\n",
    "(model, optimal_window_size, optimal_batch_size, optimal_learning_rate) = bo_lstm_hyperparams(dataset,num_epochs = 10, \n",
    "                                                                                              bo_iteration_number=15, display_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3114ce4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koishikawa\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian optimization iteration : 1 / 3\n",
      "Best score : -0.19786013490489673\n",
      "==========\n",
      "Bayesian optimization iteration : 2 / 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koishikawa\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\koishikawa\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\koishikawa\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\koishikawa\\BO_LSTM\\bo_lstm.py:307: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  next_samples = pd.concat([next_samples, bo_x_prediction.loc[acquisition_function_prediction.idxmax()]], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score : -0.024514036792679494\n",
      "==========\n",
      "Bayesian optimization iteration : 3 / 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koishikawa\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\koishikawa\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\koishikawa\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\koishikawa\\BO_LSTM\\bo_lstm.py:307: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  next_samples = pd.concat([next_samples, bo_x_prediction.loc[acquisition_function_prediction.idxmax()]], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score : -0.024514036792679494\n",
      "==========\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bo_lstm import bo_lstm_hyperparams\n",
    "\n",
    "#データセットの読み込み\n",
    "dataset = pd.read_csv('sample_dataset.csv', index_col=0)\n",
    "\n",
    "(model, optimal_window_size, optimal_batch_size, optimal_learning_rate) = bo_lstm_hyperparams(dataset,num_epochs = 10, \n",
    "                                                                                              bo_iteration_number=3, display_flag=True, bo_iteration_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0497d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seq_length = int(optimal_window_size)\n",
    "hidden_dim = int(optimal_hidden_dim)\n",
    "output_dim = 1\n",
    "batch_size = int(optimal_batch_size)\n",
    "num_epochs = 100\n",
    "use_attention = optimal_attention  # Attention層を使うかどうかを選択 (True or False)\n",
    "fold_number = 5  # N-fold CV の N\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# データ読み込みと前処理（変更なし）\n",
    "# -------------------------------\n",
    "\n",
    "dataset = pd.read_csv('sample_dataset.csv', index_col=0)\n",
    "\n",
    "data = dataset.values.astype('float32')\n",
    "\n",
    "inputs = data[:, 1:]\n",
    "targets = data[:, 0]\n",
    "\n",
    "#ここで入力の次元が決まります\n",
    "input_dim = dataset.shape[1] - 1\n",
    "\n",
    "def create_sequences(data, target, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        xs.append(data[i:i+seq_length])\n",
    "        ys.append(target[i+seq_length])\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "input_sequences, target_sequences = create_sequences(inputs, targets, seq_length)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    input_sequences, target_sequences, test_size=0.3, shuffle=False)\n",
    "\n",
    "train_inputs_tensor = torch.tensor(X_train).float()\n",
    "train_targets_tensor = torch.tensor(y_train).float().unsqueeze(1)\n",
    "\n",
    "test_inputs_tensor = torch.tensor(X_test).float()\n",
    "test_targets_tensor = torch.tensor(y_test).float().unsqueeze(1)\n",
    "\n",
    "train_dataset = TensorDataset(train_inputs_tensor, train_targets_tensor)\n",
    "test_dataset = TensorDataset(test_inputs_tensor, test_targets_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "model = LSTMWithOptionalAttention(input_dim, hidden_dim, output_dim, use_attention, optimal_dropout_rate)\n",
    "\n",
    "# -------------------------------\n",
    "# 学習準備（変更なし）\n",
    "# -------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=optimal_learning_rate)\n",
    "\n",
    "# -------------------------------\n",
    "# モデル学習（Attentionの重みは必要に応じて取得）\n",
    "# -------------------------------\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_dataset)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "# -------------------------------\n",
    "# モデル評価（Attentionの重みは必要に応じて保存）\n",
    "# -------------------------------\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "all_test_predictions = []\n",
    "all_true_test_targets = []\n",
    "all_attention_weights = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs, attention_weights = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        all_test_predictions.extend(outputs.cpu().numpy().flatten())\n",
    "        all_true_test_targets.extend(targets.cpu().numpy().flatten())\n",
    "        if use_attention:\n",
    "            all_attention_weights.extend(attention_weights.cpu().numpy())\n",
    "\n",
    "average_test_loss = test_loss / len(test_dataset)\n",
    "r2 = r2_score(all_true_test_targets, all_test_predictions)\n",
    "#r2 = r2lm(all_true_test_targets, all_test_predictions)\n",
    "mae = mean_absolute_error(all_true_test_targets, all_test_predictions)\n",
    "rmse = np.sqrt(mean_squared_error(all_true_test_targets, all_test_predictions))\n",
    "\n",
    "print(f'\\n平均テスト損失: {average_test_loss:.4f}')\n",
    "print(f'R2: {r2:.4f}')\n",
    "print(f'MAE: {mae:.4f}')\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "\n",
    "# -------------------------------\n",
    "# プロット（Attentionの可視化はuse_attentionがTrueの場合のみ）\n",
    "# -------------------------------\n",
    "# 学習曲線（変更なし）\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# テスト結果（変更なし）\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(all_true_test_targets, label='Actual')\n",
    "plt.plot(all_test_predictions, label='Predicted')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Test Data: Actual vs Predicted')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Attentionの可視化（use_attentionがTrueの場合のみ）\n",
    "if use_attention and all_attention_weights:\n",
    "    first_attention = all_attention_weights[0] # (seq_len, seq_len)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(first_attention, cmap='viridis', aspect='auto')\n",
    "    plt.colorbar(label='Attention Weight')\n",
    "    plt.title('Attention Weights for the First Test Sample')\n",
    "    plt.xlabel('Input Time Step')\n",
    "    plt.ylabel('Attention to Time Step')\n",
    "    plt.xticks(range(seq_length))\n",
    "    plt.yticks(range(seq_length))\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b1bb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
